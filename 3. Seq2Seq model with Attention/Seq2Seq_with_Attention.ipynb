{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from ..\\utils\\dataset_loader.ipynb\n",
      "importing Jupyter notebook from ..\\utils\\training.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "from utils.dataset_loader import CreateDataset\n",
    "from utils.training import Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### cpu, gpu 선택\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "### 불용어 사용 여부\n",
    "use_stopword = True\n",
    "\n",
    "### batch_size\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading training.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".data\\multi30k\\training.tar.gz: 100%|██████████████████████████████████████████████| 1.21M/1.21M [00:02<00:00, 469kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading validation.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".data\\multi30k\\validation.tar.gz: 100%|███████████████████████████████████████████| 46.3k/46.3k [00:00<00:00, 77.2kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading mmt_task1_test2016.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".data\\multi30k\\mmt_task1_test2016.tar.gz: 100%|████████████████████████████████████| 66.2k/66.2k [00:00<00:00, 116kB/s]\n"
     ]
    }
   ],
   "source": [
    "### 미리 만들어둔 데이터셋을 가져옴\n",
    "dataset = CreateDataset(device=device, use_stopword=use_stopword)\n",
    "\n",
    "### 데이터셋에서 iterator만 뽑아냄\n",
    "train_iterator, valid_iterator, test_iterator = dataset.get_iterator(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.rnn = nn.GRU(emb_dim, enc_hid_dim, num_layers=n_layers, dropout=dropout, bidirectional=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(enc_hid_dim*2, dec_hid_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x = [src_len, batch_size]\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(x))\n",
    "        # embedded = [src_len, batch_size, emb_dim]\n",
    "        \n",
    "        outputs, hidden = self.rnn(embedded)\n",
    "        # outputs = [src_len, batch_size, hid_dim*2]\n",
    "        # hidden = [num_layers*directional, batch_size, hid_dim]\n",
    "        \n",
    "        hidden = torch.cat([hidden[-2], hidden[-1]], dim=1)\n",
    "        hidden = self.fc(hidden)\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
    "        super().__init__()\n",
    "        self.energy = nn.Linear(enc_hid_dim*2 + dec_hid_dim, dec_hid_dim)\n",
    "        self.v = nn.Linear(dec_hid_dim, 1, bias=False)\n",
    "        \n",
    "    def forward(self, encoder_outputs, hidden):\n",
    "        # encoder_outputs = [src_len, batch_size, enc_hid_dim*2]\n",
    "        # hidden = [batch_size, dec_hid_dim]\n",
    "        \n",
    "        src_len = encoder_outputs.shape[0]\n",
    "        batch_size = encoder_outputs.shape[1]\n",
    "        \n",
    "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
    "        # hidden = [batch_size, src_len, dec_hid_dim]\n",
    "        \n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
    "        # encoder_outputs = [batch_size, src_len, enc_hid_dim*2]\n",
    "        \n",
    "        temp = torch.cat((encoder_outputs, hidden), dim=2)\n",
    "        \n",
    "        energy = torch.tanh(self.energy(temp))\n",
    "        # energy = [batch_size, src_len, dec_hid_dim]\n",
    "        \n",
    "        v = self.v(energy).squeeze(2)\n",
    "        # v = [batch_size, src_len, 1]\n",
    "        \n",
    "        return F.softmax(v, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, n_layers, dropout, atte):\n",
    "        super().__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.atte = atte\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.rnn = nn.GRU(emb_dim+enc_hid_dim*2, dec_hid_dim, num_layers=n_layers, dropout=dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc_out = nn.Linear(dec_hid_dim+enc_hid_dim*2+emb_dim, output_dim)\n",
    "        \n",
    "    def forward(self, trg, encoder_outputs, hidden):\n",
    "        # trg = [batch_size]\n",
    "        # encoder_outputs = [src_len, batch_size, enc_hid_dim*2]\n",
    "        # hidden = [batch_size, dec_hid_dim]\n",
    "        \n",
    "        trg = trg.unsqueeze(0)\n",
    "        # trg = [1, batch_size]\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(trg))\n",
    "        # embedded = [1, batch_size, emb_dim]\n",
    "        \n",
    "        a = self.atte(encoder_outputs, hidden)\n",
    "        # a = [batch_size, src_len]\n",
    "        \n",
    "        a = a.unsqueeze(1)\n",
    "        # a = [batch_size, 1, src_len]\n",
    "        \n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
    "        # encoder_outputs = [batch_size, src_len, enc_hid_dim*2]\n",
    "        \n",
    "        weighted = torch.bmm(a, encoder_outputs)\n",
    "        # weighted = [batch_size, 1, enc_hid_dim*2]\n",
    "        \n",
    "        weighted = weighted.permute(1, 0, 2)\n",
    "        # weighted = [1, batch_size, enc_hid_dim*2]\n",
    "        \n",
    "        rnn_output, hidden = self.rnn(torch.cat((embedded, weighted), axis=2), hidden.unsqueeze(0))\n",
    "        # output = [1, batch_size, dec_hid_dim]\n",
    "        # hidden = [1, batch_size, dec_hid_dim]\n",
    "        \n",
    "        output = self.fc_out(torch.cat((embedded.squeeze(0), weighted.squeeze(0), rnn_output.squeeze(0)), dim=1))\n",
    "        \n",
    "        return output, hidden.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, enc, dec, device):\n",
    "        super().__init__()\n",
    "        self.enc = enc\n",
    "        self.dec = dec\n",
    "        self.device = device\n",
    "        \n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "        encoder_outputs, hidden = self.enc(src)\n",
    "        \n",
    "        trg_len = trg.shape[0]\n",
    "        batch_size = trg.shape[1]\n",
    "        output_dim = self.dec.output_dim\n",
    "        \n",
    "        outputs = torch.zeros(trg_len, batch_size, output_dim).to(self.device)\n",
    "        \n",
    "        dec_input = trg[0]\n",
    "        \n",
    "        for t in range(1, trg_len):\n",
    "            output, hidden = self.dec(dec_input, encoder_outputs, hidden)\n",
    "            \n",
    "            outputs[t] = output\n",
    "            \n",
    "            top1 = torch.argmax(output, dim=1)\n",
    "            \n",
    "            dec_input = top1 if random.random() > teacher_forcing_ratio else trg[t]\n",
    "            \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(dataset.SRC.vocab)\n",
    "output_dim = len(dataset.TRG.vocab)\n",
    "emb_dim = 256\n",
    "enc_hid_dim = 512\n",
    "dec_hid_dim = 512\n",
    "n_layers = 1\n",
    "dropout = 0.1\n",
    "clip = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = Encoder(input_dim, emb_dim, enc_hid_dim, dec_hid_dim, n_layers, dropout).to(device)\n",
    "att = Attention(enc_hid_dim, dec_hid_dim)\n",
    "dec = Decoder(output_dim, emb_dim, enc_hid_dim, dec_hid_dim, n_layers, dropout, att).to(device)\n",
    "\n",
    "model = Seq2Seq(enc, dec, device).to(device)\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_index = dataset.TRG.vocab.stoi[dataset.TRG.pad_token]\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_index)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (enc): Encoder(\n",
       "    (embedding): Embedding(7854, 256)\n",
       "    (rnn): GRU(256, 512, dropout=0.1, bidirectional=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (fc): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  )\n",
       "  (dec): Decoder(\n",
       "    (atte): Attention(\n",
       "      (energy): Linear(in_features=1536, out_features=512, bias=True)\n",
       "      (v): Linear(in_features=512, out_features=1, bias=False)\n",
       "    )\n",
       "    (embedding): Embedding(5893, 256)\n",
       "    (rnn): GRU(1280, 512, dropout=0.1)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (fc_out): Linear(in_features=1792, out_features=5893, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 20,518,661 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 907/907 [01:27<00:00, 10.40it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 39.22it/s]\n",
      "  0%|                                                                                  | 1/907 [00:00<02:03,  7.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.667336062533327 4.424718506634235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 907/907 [01:27<00:00, 10.39it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 38.98it/s]\n",
      "  0%|                                                                                  | 1/907 [00:00<01:59,  7.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7689433184584815 3.7666036933660507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 907/907 [01:31<00:00,  9.92it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 40.30it/s]\n",
      "  0%|                                                                                  | 1/907 [00:00<01:41,  8.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.211208418685257 3.472137860953808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 907/907 [01:27<00:00, 10.34it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 37.56it/s]\n",
      "  0%|                                                                                  | 1/907 [00:00<01:45,  8.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.884414926253448 3.328101582825184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 907/907 [01:29<00:00, 10.10it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 38.05it/s]\n",
      "  0%|                                                                                  | 1/907 [00:00<02:00,  7.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6453256806833085 3.249452695250511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 907/907 [01:27<00:00, 10.38it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 38.79it/s]\n",
      "  0%|                                                                                  | 1/907 [00:00<02:02,  7.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.460940697621616 3.1917189955711365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 907/907 [01:30<00:00, 10.03it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 38.84it/s]\n",
      "  0%|                                                                                  | 1/907 [00:00<02:19,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2967005462078696 3.180644206702709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 907/907 [01:27<00:00, 10.35it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 37.78it/s]\n",
      "  0%|                                                                                  | 1/907 [00:00<01:58,  7.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1566983641442548 3.1480888202786446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 907/907 [01:27<00:00, 10.35it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 38.32it/s]\n",
      "  0%|                                                                                  | 1/907 [00:00<01:40,  9.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0298493712844765 3.1237141638994217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 907/907 [01:32<00:00,  9.82it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 38.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.920609183847707 3.1472686752676964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "learn = Learning()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model, train_loss = learn.train(model, criterion, optimizer, train_iterator, clip)\n",
    "    eval_loss = learn.evaluation(model, criterion, valid_iterator)\n",
    "    print(train_loss, eval_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
